{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZatFYG9IYss"
   },
   "source": [
    "# Lab 4: Data Wrangling [Total: 5 Points]\n",
    "\n",
    "## Important\n",
    "* Please ensure that you run the following two cells below before running any others. This will download all required files, as well as installing the necessary packages to ensure the code runs successfully. If you restart the kernel or your runtime session (in Colab), be sure to rerun this cell before running any others.\n",
    "* This assignment recommends using **Google Colab**. If you are using **Anaconda Jupyter notebook/lab**, please ensure that this notebook is kept in a new folder. This is because the following commands will delete all files with the extensions .csv and .py before downloading the required files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "475Ivp1oQFG9"
   },
   "outputs": [],
   "source": [
    "required_files = \"https://github.com/mainuddin-rony/inst447-fall2024/raw/main/assignment/lab/lab4/required_files.zip\"\n",
    "! rm -rf tests\n",
    "! rm -f required_files.zip *.csv *.py ._*.csv\n",
    "! wget $required_files && unzip -j required_files.zip\n",
    "! mkdir tests && mv *.py tests\n",
    "! pip install otter-grader==5.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "VcKAE9Lo-1Jg"
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6zDhV4x-1Ji",
    "jupyter": {
     "outputs_hidden": true
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27f43f5390430eb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Instructions\n",
    "\n",
    "The purpose of this assignment is for you to practice with common data wrangling operations, such as converting from long to wide format, merging, reshaping, and aggregating data frames. You will carry out this task in the present notebook, and use the notebook to document the various steps of the exercise and to answer all questions.\n",
    "\n",
    "You will be working with a dataset describing orders made by customers. We have created a number of datasets for the purpose. A data dictionary listing all columns and their meaning is provided below. Follow the instructions in each question, and answer the accompanying questions. Note that some of the questions will require you to write a Python function to compute the correct answer.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "This assignment will be graded automatically. To grade your submission we will run your code into the autograder. The autograder will compare the value returned by your function (i.e. the student's answer) against the correct answer. The autograder code itself is not included in this notebook, so double check that your code works correctly before submitting.\n",
    "</div>\n",
    "\n",
    "## Required skills\n",
    "\n",
    "This lab will let you practice the following skills:\n",
    "- Converting from long to wide\n",
    "- Merging data frames\n",
    "- Reshaping data frames\n",
    "- Aggregating data frames\n",
    "\n",
    "Before you start working on it, review Chapter 3 (p. 141â€’157) of the textbook and/or the notebooks posted on ELMS under \"Data Wrangling module\".\n",
    "\n",
    "\n",
    "## Data dictionary\n",
    "\n",
    "This LAB includes multiple data files about an e-commerce website and grocery store, each corresponding to a different pandas table/data frame.\n",
    "\n",
    "### File `orders.csv`\n",
    "\n",
    "Each row in this table represents an order made by a particular customer. An order may contain multiple products.\n",
    "- `order_id` &ndash; Unique order identifier;\n",
    "- `user_id` &ndash; Unique user identifier;\n",
    "- `order_number` &ndash; Order number (how many times a particular user has ordered using this service);\n",
    "- `order_dow` &ndash; Day of week of the order (`0` &ndash; Monday &#8230; `6` &ndash; Sunday);\n",
    "- `order_hour_of_day` &ndash; Hour of the day the order was placed;\n",
    "- `days_since_prior_order` &ndash; Number of days since the user's previous order;\n",
    "\n",
    "### File `products.csv`\n",
    "\n",
    "Each row in this table represents a product in the store's inventory.\n",
    "- `product_id` &ndash; Product ID (unique identifier for each product);\n",
    "- `product_name` &ndash; Product name;\n",
    "- `aisle_id` &ndash; Aisle ID (unique identifier for each aisle);\n",
    "- `department_id` &ndash; Department ID (unique identifier for each department);\n",
    "\n",
    "### File `order_products.csv`\n",
    "\n",
    "Each row in this table information about a particular product that is part of an order.\n",
    "- `order_id` &ndash; Unique order identifier;\n",
    "- `product_id` &ndash; Product ID (Unique identifier for each product);\n",
    "- `add_to_cart_order` &ndash; Order in which product was added to cart;\n",
    "- `reordered` &ndash; Was the item reordered?\n",
    "\n",
    "### File `OrganicAisle.csv`\n",
    "\n",
    "Each row in this table contains information about a particular aisle. Only organic products are included in this table.\n",
    "- `aisle_id` &ndash; Aisle ID (unique identifier for each aisle);\n",
    "- `num_items` &ndash; Number of items ordered;\n",
    "- `aisle` &ndash; Aisle name;\n",
    "\n",
    "### File `ConventionalAisle.csv`\n",
    "Each row in this table contains information about a particular aisle. Only conventional products are included in this table.\n",
    "- `aisle_id` &ndash; Aisle ID (Unique identifier for each aisle);\n",
    "- `num_items` &ndash; Number of items ordered;\n",
    "- `aisle` &ndash; Aisle name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvF2tlJC-1Jk",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-696dc5e2897f8fec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q1\n",
    "\n",
    "**Points**: 1\n",
    "\n",
    "Write a function to called `busiest_dow` that takes a `filename` as a parameter and returns the day of the week with most orders.\n",
    "\n",
    "Please make sure to provide the most suitable file as a parameter for this task. The function should then load the data into a data frame and return a Python integer (type `int`, not `int64`) representing a day of the week, with `0` for Monday and `6` for Sunday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyden2lI-1Jl",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-44ca4ed965cf7c63",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def busiest_dow(filename):\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TcfgBOGD-1Jl",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e33b294de613dbc4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the cell below to run your function and see what it returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "amfhy3br-1Jm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = ... ## Mention the name of the file here\n",
    "busiest_dow(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rw-T1hKv-1Jn"
   },
   "source": [
    "This cell will autograde your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ahMR0u3l-1Jn"
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNqcfmDS-1Jn"
   },
   "source": [
    "## Q2\n",
    "\n",
    "**Points**: 1\n",
    "\n",
    "Write a function called `items_per_order` that returns the number of items in each order.\n",
    "\n",
    "Your function should not take any parameter. It should load the appropriate data file and it should return a pandas data frame, indexed by order ID, with the result stored in a column named `num_items`.\n",
    "\n",
    "_**Hint**: this question requires to combine multiple datasets together before you can compute the aggregate column. Also, to rename a column after using groupby you can either use the `.rename()` method from the DataFrame class or the [Named Aggregation](https://pandas.pydata.org/docs/user_guide/groupby.html#named-aggregation) special syntax directly._\n",
    "\n",
    "The resulting data frame should have exactly 5,000 rows. This is what the top 5 rows should look like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>num_items</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>order_id</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>657</th>\n",
    "      <td>19</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2203</th>\n",
    "      <td>29</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2255</th>\n",
    "      <td>12</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2654</th>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2755</th>\n",
    "      <td>4</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "and these are the bottom 5:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>num_items</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>order_id</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>3417262</th>\n",
    "      <td>11</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3417499</th>\n",
    "      <td>16</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3418430</th>\n",
    "      <td>4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3419803</th>\n",
    "      <td>16</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3420412</th>\n",
    "      <td>4</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMGxsDZh-1Jn",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b2cd70a216d52f0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def items_per_order():\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cwLu1EPj-1Jo"
   },
   "source": [
    "Use the cell below to run your function and see what it returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "G_tC7xaL-1Jo"
   },
   "outputs": [],
   "source": [
    "items_per_order()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "umfOLjb7-1Jo"
   },
   "source": [
    "This cell will autograde your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hN3JCdWh-1Jp"
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ATcOdUp-1Jp",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee9d643da78ba714",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q3\n",
    "\n",
    "**Points**: 1\n",
    "\n",
    "Write a function called `avg_orders_by_dow` that returns the average number of orders (rounded to two decimals) for each day of the week.\n",
    "\n",
    "Your function should not take any parameter. It should load the appropriate file(s) for this task into a data frame and it should return a pandas data frame, indexed by the day of the week, and with a column named `avg_orders`.\n",
    "\n",
    "_**Hint**:  This question builds upon the previous one. To store the number of items into the orders data frame, make sure that to use the [.set_index()](https://pandas.pydata.org/docs/user_guide/indexing.html#set-reset-index) method on the Order ID column, otherwise you will get NaN._\n",
    "\n",
    "This is what the data frame should look like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>avg_orders</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>order_dow</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>11.15</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>10.39</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>9.47</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>9.21</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>9.58</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>9.66</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>11.25</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0L2OIS6l-1Jp",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0b8f2397c0bc7a9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def avg_orders_by_dow():\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HnwFgY4g-1Jp",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a463a1b05738292",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the cell below to run your function and see what it returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "BdZjKqRU-1Jp"
   },
   "outputs": [],
   "source": [
    "avg_orders_by_dow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GdoRs9_A-1Jp"
   },
   "source": [
    "This cell will autograde your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yF3SjEnr-1Jq"
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkgIN-82-1Jq",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28ec6c1633fd2ac2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q4\n",
    "\n",
    "**Points**: 1\n",
    "\n",
    "Write a function to select only organic aisles that have exactly 1 item only.\n",
    "\n",
    "Your function should not take any parameter. It should load the appropriate file for this task into a data frame and it should return a pandas data frame.\n",
    "\n",
    "This is what the data frame should look like:\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>aisle_id</th>\n",
    "      <th>num_items</th>\n",
    "      <th>aisle</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>40</th>\n",
    "      <td>44</td>\n",
    "      <td>1</td>\n",
    "      <td>eye ear care</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>77</th>\n",
    "      <td>87</td>\n",
    "      <td>1</td>\n",
    "      <td>more household</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>113</th>\n",
    "      <td>124</td>\n",
    "      <td>1</td>\n",
    "      <td>spirits</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_i0HgGjb-1Jq",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8cde0aadbd4febd5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def single_item_organic():\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UOOXMbba-1Jq",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c7d07545b1066f41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the cell below to run your function and see what it returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "BLP4VRtj-1Jq"
   },
   "outputs": [],
   "source": [
    "single_item_organic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vtDg0_Go-1Jq"
   },
   "source": [
    "This cell will autograde your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1n-g6bvr-1Jq"
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sh_jInD7-1Jr",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-09499b2871aebd6a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q5\n",
    "\n",
    "**Points**: 1\n",
    "\n",
    "We want to know how many aisles have both organic and conventional items.\n",
    "\n",
    "Write a function called `aisles_both` that combines the `organic` and `conventional` data sets into a single data frame.\n",
    "\n",
    "Your function should not take any parameter. It should load the appropriate file(s) for this task into a data frame and it should return a pandas data frame.\n",
    "\n",
    "_**Hint**: You may find it useful to use Pandas `merge` function. Since both data frames have common column names, make sure to specify the suffixes for any column with a common name, and to drop any redundant column._\n",
    "\n",
    "Your data frame should have exactly 123 rows. This is what the first 5 rows should look like:\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>aisle_id</th>\n",
    "      <th>num_items_org</th>\n",
    "      <th>num_items_conv</th>\n",
    "      <th>aisle</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>1</td>\n",
    "      <td>895</td>\n",
    "      <td>2679</td>\n",
    "      <td>prepared soups salads</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>2</td>\n",
    "      <td>36</td>\n",
    "      <td>3801</td>\n",
    "      <td>specialty cheeses</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>3</td>\n",
    "      <td>2289</td>\n",
    "      <td>15134</td>\n",
    "      <td>energy granola bars</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>4</td>\n",
    "      <td>1320</td>\n",
    "      <td>8539</td>\n",
    "      <td>instant foods</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>5</td>\n",
    "      <td>191</td>\n",
    "      <td>2623</td>\n",
    "      <td>marinades meat preparation</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "and the bottom 5 rows:\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>aisle_id</th>\n",
    "      <th>num_items_org</th>\n",
    "      <th>num_items_conv</th>\n",
    "      <th>aisle</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>118</th>\n",
    "      <td>129</td>\n",
    "      <td>496</td>\n",
    "      <td>8228</td>\n",
    "      <td>frozen appetizers sides</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>119</th>\n",
    "      <td>130</td>\n",
    "      <td>1528</td>\n",
    "      <td>4848</td>\n",
    "      <td>hot cereal pancake mixes</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>120</th>\n",
    "      <td>131</td>\n",
    "      <td>2613</td>\n",
    "      <td>8498</td>\n",
    "      <td>dry pasta</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>121</th>\n",
    "      <td>132</td>\n",
    "      <td>2</td>\n",
    "      <td>244</td>\n",
    "      <td>beauty</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>122</th>\n",
    "      <td>133</td>\n",
    "      <td>2</td>\n",
    "      <td>895</td>\n",
    "      <td>muscles joints pain relief</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyaFLpR1-1Jr",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c4ac5bef27199118",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aisles_both():\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5i-6lIxF-1Jr",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a55b0b925a54cf42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the cell below to run your function and see what it returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OVjjDzOc-1Jr"
   },
   "outputs": [],
   "source": [
    "aisles_both()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UNpnpMTz-1Jr"
   },
   "source": [
    "This cell will autograde your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mpiGJN6g-1Jr"
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1sKvzepW-1Jr"
   },
   "source": [
    "## Submission\n",
    "\n",
    "Don't forget to run all cells in your notebook and then save it. To save, click on `File`, then select `Save/Save Notebook`. After that, download the notebook by going to `File`, then `Download` (for Anaconda notebook), and choosing `Download .ipynb` (for Colab). Finally, submit the notebook on Gradescope using the link found on ELMS."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "otter": {
   "OK_FORMAT": false,
   "tests": {
    "q1": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q1\"\npoints = None\n\n@test_case(points=None, hidden=False)\ndef test1_busiest_dow(busiest_dow):\n    import pandas as pd\n    q1file = 'orders.csv'\n    q1CORRECT_ANS = 0\n    q1STUDENT_ANS = busiest_dow(q1file)\n\n    assert type(q1STUDENT_ANS) == int, f\"Error: Your solution returned a {type(q1STUDENT_ANS)} while it should return an int\"\n    assert q1STUDENT_ANS == q1CORRECT_ANS, f\"Error: Your solution returned {q1STUDENT_ANS}. Correct answer: {q1CORRECT_ANS}\"\n\n@test_case(points=None, hidden=False)\ndef test2_busiest_dow(busiest_dow):\n    import pandas as pd\n    q2file = 'q1_test.csv'\n    q2CORRECT_ANS = 1\n    q2STUDENT_ANS = busiest_dow(q2file)\n\n    assert type(q2STUDENT_ANS) == int, f\"Error: Your solution returned a {type(q2STUDENT_ANS)} while it should return an int\"\n    assert q2STUDENT_ANS == q2CORRECT_ANS, f\"Error: Your solution returned {q2STUDENT_ANS}. Correct answer: {q2CORRECT_ANS}\"\n\n",
    "q2": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q2\"\npoints = None\n\n@test_case(points=None, hidden=False)\ndef test1_items_per_order(items_per_order):\n    import pandas as pd\n    from pandas.testing import assert_frame_equal\n    q2CORRECT_ANSWER = pd.read_csv(\"solutionq2.csv\", index_col=0)\n    q2STUDENT_ANSWER = items_per_order()\n    \n    assert type(q2STUDENT_ANSWER) is pd.DataFrame, f\"Error: expected DataFrame, got {type(q2STUDENT_ANSWER)} instead.\"\n    try:\n        assert_frame_equal(q2STUDENT_ANSWER, q2CORRECT_ANSWER)\n    except AssertionError:\n        idx = q2STUDENT_ANSWER != q2CORRECT_ANSWER\n        correct = q2CORRECT_ANSWER[idx].dropna().to_string()\n        incorrect = q2STUDENT_ANSWER[idx].dropna().to_string()\n        raise AssertionError(f\"Returned dataframe doesn't match. Mismatches are: \\n ===== Correct ===== \\n {correct} \\n\\n ===== Incorrect ===== \\n {incorrect}\")\n\n",
    "q3": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q3\"\npoints = None\n\n@test_case(points=None, hidden=False)\ndef test1_avg_orders_by_dow(avg_orders_by_dow):\n    import pandas as pd\n    from pandas.testing import assert_frame_equal\n    from io import StringIO\n    q3CORRECT_ANSWER = \"\"\"order_dow,avg_orders\n0,11.15\n1,10.39\n2,9.47\n3,9.21\n4,9.58\n5,9.66\n6,11.25\"\"\"\n    q3CORRECT_ANSWER = pd.read_csv(StringIO(q3CORRECT_ANSWER), index_col=0)\n    q3STUDENT_ANSWER = avg_orders_by_dow()\n    \n    assert type(q3STUDENT_ANSWER) is pd.DataFrame, f\"Error: expected DataFrame, got {type(q3STUDENT_ANSWER)} instead.\"\n    try:\n        assert_frame_equal(q3STUDENT_ANSWER, q3CORRECT_ANSWER)\n    except AssertionError:\n        idx = q3STUDENT_ANSWER != q3CORRECT_ANSWER\n        correct = q3CORRECT_ANSWER[idx].dropna().to_string()\n        incorrect = q3STUDENT_ANSWER[idx].dropna().to_string()\n        raise AssertionError(f\"Returned dataframe doesn't match. Mismatches are: \\n ===== Correct ===== \\n {correct} \\n\\n ===== Incorrect ===== \\n {incorrect}\")\n\n",
    "q4": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q4\"\npoints = None\n\n@test_case(points=None, hidden=False)\ndef test1_single_item_organic(single_item_organic):\n    import pandas as pd\n    from pandas.testing import assert_frame_equal\n    from io import StringIO\n    q4CORRECT_ANSWER = \"\"\",aisle_id,num_items,aisle\n40,44,1,eye ear care\n77,87,1,more household\n113,124,1,spirits\"\"\"\n    q4CORRECT_ANSWER = pd.read_csv(StringIO(q4CORRECT_ANSWER), index_col=0)\n    q4STUDENT_ANSWER = single_item_organic()\n    \n    assert type(q4STUDENT_ANSWER) is pd.DataFrame, f\"Error: expected DataFrame, got {type(q4STUDENT_ANSWER)} instead.\"\n    try:\n        assert_frame_equal(q4STUDENT_ANSWER, q4CORRECT_ANSWER)\n    except AssertionError:\n        idx = q4STUDENT_ANSWER != q4CORRECT_ANSWER\n        correct = q4CORRECT_ANSWER[idx].dropna().to_string()\n        incorrect = q4STUDENT_ANSWER[idx].dropna().to_string()\n        raise AssertionError(f\"Returned dataframe doesn't match. Mismatches are: \\n ===== Correct ===== \\n {correct} \\n\\n ===== Incorrect ===== \\n {incorrect}\")\n        \n",
    "q5": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q5\"\npoints = None\n\n@test_case(points=None, hidden=False)\ndef test1_aisles_both(aisles_both):\n    import pandas as pd\n    from pandas.testing import assert_frame_equal\n    from io import StringIO\n    q5CORRECT_ANSWER = \"\"\",aisle_id,num_items_org,num_items_conv,aisle\n0,1,895,2679,prepared soups salads\n1,2,36,3801,specialty cheeses\n2,3,2289,15134,energy granola bars\n3,4,1320,8539,instant foods\n4,5,191,2623,marinades meat preparation\n5,6,271,1703,other\n6,7,160,1079,packaged meat\n7,8,34,1498,bakery desserts\n8,9,2452,7984,pasta sauce\n9,11,4,1342,cold flu allergy\n10,12,378,1437,fresh pasta\n11,13,147,4010,prepared meals\n12,14,2556,2546,tofu meat alternatives\n13,16,8467,5339,fresh herbs\n14,17,2275,10529,baking ingredients\n15,18,76,585,bulk dried fruits vegetables\n16,19,2725,7852,oils vinegars\n17,20,16,3056,oral hygiene\n18,21,7007,34326,packaged cheese\n19,22,7,1462,hair care\n20,23,567,6350,popcorn jerky\n21,24,64076,75696,fresh fruits\n22,25,54,2711,soap\n23,26,593,7790,coffee\n24,27,11,1828,beers coolers\n25,28,8,1235,red wines\n26,29,1229,1574,honeys syrups nectars\n27,30,527,3212,latino foods\n28,31,5757,18701,refrigerated\n29,32,6363,13252,packaged produce\n30,33,3,628,kosher foods\n31,34,136,2830,frozen meat seafood\n32,35,1232,3926,poultry counter\n33,36,1606,8975,butter\n34,37,1249,21419,ice cream ice\n35,38,1201,16350,frozen meals\n36,40,43,1569,dog food care\n37,41,9,2876,cat food care\n38,42,76,4651,frozen vegan vegetarian\n39,43,103,4951,buns rolls\n40,44,1,547,eye ear care\n41,45,2318,9171,candy chocolate\n42,46,5,959,mint gum\n43,47,188,1826,vitamins supplements\n44,48,228,2916,breakfast bars pastries\n45,49,1067,5321,packaged poultry\n46,50,2384,4340,fruit vegetable snacks\n47,51,968,4210,preserved dips spreads\n48,52,2493,7236,frozen breakfast\n49,53,3891,8465,cream\n50,55,5,527,shave needs\n51,57,938,2835,granola\n52,58,77,1455,frozen breads doughs\n53,59,4868,6595,canned meals beans\n54,61,171,9853,cookies cakes\n55,62,4,1084,white wines\n56,63,4168,2976,grains rice dried goods\n57,64,158,4536,energy sports drinks\n58,65,263,1363,protein meal replacements\n59,66,2843,5688,asian foods\n60,67,1356,13965,fresh dips tapenades\n61,68,413,144,bulk grains rice dried goods\n62,69,7778,6906,soup broth bouillon\n63,70,187,1018,digestion\n64,71,154,1575,refrigerated pudding desserts\n65,72,2602,7111,condiments\n66,73,2,744,facial care\n67,76,67,719,indian foods\n68,77,147,16147,soft drinks\n69,78,3012,16543,crackers\n70,79,699,6962,frozen pizza\n71,80,17,841,deodorants\n72,81,4993,7147,canned jarred vegetables\n73,83,72194,77468,fresh vegetables\n74,84,17594,15315,milk\n75,85,194,2906,food storage\n76,86,10047,9828,eggs\n77,87,1,890,more household\n78,88,2367,9762,spreads\n79,89,803,3916,salad dressing toppings\n80,90,20,1043,cocoa drink mixes\n81,91,5246,19272,soy lactosefree\n82,92,5983,7215,baby food formula\n83,93,1327,8524,breakfast bakery\n84,94,2215,7159,tea\n85,95,22,3219,canned meat seafood\n86,96,2916,14044,lunch meat\n87,97,115,1036,baking supplies decor\n88,98,3082,9987,juice nectars\n89,99,1418,2650,canned fruit applesauce\n90,100,7531,5060,missing\n91,101,3,1065,air fresheners candles\n92,102,3,325,baby bath body care\n93,103,137,391,ice cream toppings\n94,104,6407,7282,spices seasonings\n95,105,205,4624,doughs gelatins bake mixes\n96,106,2458,10327,hot dogs bacon sausage\n97,107,3345,27930,chips pretzels\n98,108,3032,9907,other creams cheeses\n99,109,17,528,skin care\n100,110,353,4267,pickled goods olives\n101,112,5448,18154,bread\n102,113,56,238,frozen juice\n103,114,8,5886,cleaning products\n104,115,27,36377,water seltzer sparkling water\n105,116,12852,13237,frozen produce\n106,117,2796,9173,nuts seeds dried fruit\n107,118,46,534,first aid\n108,119,23,900,frozen dessert\n109,120,10659,44710,yogurt\n110,121,2870,13369,cereal\n111,122,152,3122,meat counter\n112,123,43794,30363,packaged vegetables fruits\n113,124,1,966,spirits\n114,125,347,1116,trail mix snack mix\n115,126,153,895,feminine care\n116,127,13,2134,body lotions soap\n117,128,1089,7296,tortillas flat bread\n118,129,496,8228,frozen appetizers sides\n119,130,1528,4848,hot cereal pancake mixes\n120,131,2613,8498,dry pasta\n121,132,2,244,beauty\n122,133,2,895,muscles joints pain relief\"\"\"\n    q5CORRECT_ANSWER = pd.read_csv(StringIO(q5CORRECT_ANSWER), index_col=0)\n    q5STUDENT_ANSWER = aisles_both()\n    \n    assert type(q5STUDENT_ANSWER) is pd.DataFrame, f\"Error: expected DataFrame, got {type(q5STUDENT_ANSWER)} instead.\"\n    try:\n        assert_frame_equal(q5STUDENT_ANSWER, q5CORRECT_ANSWER)\n    except AssertionError:\n        idx = q5STUDENT_ANSWER != q5CORRECT_ANSWER\n        correct = q5CORRECT_ANSWER[idx].dropna().to_string()\n        incorrect = q5STUDENT_ANSWER[idx].dropna().to_string()\n        raise AssertionError(f\"Returned dataframe doesn't match. Mismatches are: \\n ===== Correct ===== \\n {correct} \\n\\n ===== Incorrect ===== \\n {incorrect}\")\n        \n"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
